# Protocolo MCP: Un Ejemplo con Spring Boot, Python, Gemini y LLaMA 3.2

![License: Apache 2.0](https://img.shields.io/badge/License-Apache_2.0-blue.svg)
![Java](https://img.shields.io/badge/SpringBoot-3.5-blue.svg)
![Python](https://img.shields.io/badge/Python-3.13-yellow.svg)
![Gemini](https://img.shields.io/badge/Gemini-DeepMind-blueviolet.svg)
![Llama3](https://img.shields.io/badge/Llama3.2-Ollama-ff69b4.svg)

Este repositorio contiene un ejemplo de implementacion de cliente-servidor MCP (Model context protocol) distribuido compuesto por:

- ğŸ–¥ï¸ **Servidor MCP** desarrollado en Spring Boot
- ğŸ¤– **Cliente MCP #1**: Spring Boot + [Llama 3.2](https://ollama.com/library/llama3) a travÃ©s de Ollama
- ğŸ **Cliente MCP #2**: Python + [Gemini](https://deepmind.google/discover/gemini/) para procesamiento de lenguaje natural

## ğŸ“¦ Estructura del proyecto
```
â””â”€â”€ spring-ai-mcp
   â”œâ”€â”€ ai-mcp-client
   â”‚  â””â”€â”€ src
   â”‚     â””â”€â”€ main
   â”‚        â”œâ”€â”€ java
   â”‚        â”‚  â””â”€â”€ edu
   â”‚        â”‚     â””â”€â”€ bo
   â”‚        â”‚        â””â”€â”€ uyunicode
   â”‚        â”‚           â””â”€â”€ ai
   â”‚        â”‚              â””â”€â”€ mcp
   â”‚        â”‚                 â””â”€â”€ client
   â”‚        â”‚                    â”œâ”€â”€ config
   â”‚        â”‚                    â”œâ”€â”€ constroller
   â”‚        â”‚                    â”œâ”€â”€ model
   â”‚        â”‚                    â””â”€â”€ services
   â”‚        â””â”€â”€ resources
   â”œâ”€â”€ ai-mcp-client-gemini
   â””â”€â”€ ai-mcp-server
      â””â”€â”€ src
         â””â”€â”€ main
            â”œâ”€â”€ java
            â”‚  â””â”€â”€ edu
            â”‚     â””â”€â”€ bo
            â”‚        â””â”€â”€ uyunicode
            â”‚           â””â”€â”€ ai
            â”‚              â””â”€â”€ mcp
            â”‚                 â””â”€â”€ server
            â”‚                    â”œâ”€â”€ config
            â”‚                    â”œâ”€â”€ entities
            â”‚                    â”œâ”€â”€ repository
            â”‚                    â”œâ”€â”€ services
            â”‚                    â””â”€â”€ tools
            â””â”€â”€ resources
```
## ğŸš€ CaracterÃ­sticas principales

- ComunicaciÃ³n bidireccional entre servidor y clientes a traves de MCP (Model context protocol)
- IntegraciÃ³n de modelos de lenguaje (LLMs) para anÃ¡lisis, respuesta y procesamiento de texto

## ğŸ› ï¸ TecnologÃ­as utilizadas

| Componente           | TecnologÃ­a                       |
|----------------------|----------------------------------|
| Servidor MCP         | Spring Boot                      |
| Cliente MCP #1       | Spring Boot + Ollama + Llama 3.2 |
| Cliente MCP #2       | Python + Gemini                  |

## ğŸ¯ Objetivo del proyecto

Demostrar cÃ³mo diferentes clientes MCP pueden interactuar con un servidor MCP y obtener las herramientas disponibles del servidor y entregarlas al modelo LLM para resolver tareas especÃ­ficas de procesamiento de lenguaje natural.

## ğŸ“š CÃ³mo ejecutar el proyecto

1. **Servidor MCP**:
    #### âœ… Requisitos:
    - Java 21
    - Apache Maven
    - PostgreSQL configurado y corriendo
    - Credenciales de la base de datos definidas en `application.properties`
   ```bash
   cd spring-ai-mcp
   mvn clean install
   java -jar target/spring-ai-mcp-1.0-SNAPSHOT.jar
    ```
2. **:Cliente Spring Boot + Ollama:**
    #### âœ… Requisitos:
    - Instala y configura Ollama
    - descargar el modelo Llama 3.2 con:
        ```bash
        ollama pull llama3.2
        ```
    - PostgreSQL configurado y corriendo
    - Credenciales de la base de datos definidas en `application.properties`
    - Java 21
    - Apache Maven
    - Antes de correr actualizar la IP y puerto del servidor MCP en `application.yml`
    ```bash
    cd ai-mcp-client
    mvn clean install
    java -jar target/ai-mcp-client-1.0-SNAPSHOT.jar
    ```
3. **Cliente Python + Gemini:**
    #### âœ… Requisitos:
    - Python 3.13
    - uv (gestor de paquetes moderno para Python)
    - API Key activa para Gemini
    - IP y puerto del servidor MCP definidos en configuraciÃ³n `mcp-client-gemini.py`
    ```bash
    cd ai-mcp-client-gemini
    uv sync
    uv run 
    ```

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la **Apache License 2.0** â€“ January 2004.  
Puedes revisar los tÃ©rminos completos en [http://www.apache.org/licenses/](http://www.apache.org/licenses/).

## ğŸ”— Referencias

- [IntroducciÃ³n al Model Context Protocol (MCP)](https://modelcontextprotocol.io/introduction): Protocolo abierto que estandariza cÃ³mo las aplicaciones proporcionan contexto a los modelos de lenguaje.
- [Function Calling con Gemini API](https://ai.google.dev/gemini-api/docs/function-calling?example=meeting): DocumentaciÃ³n oficial sobre cÃ³mo Gemini puede invocar funciones externas para realizar acciones reales.
- [MCP en Spring AI](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html): GuÃ­a de integraciÃ³n de MCP en aplicaciones Spring Boot usando Spring AI.
